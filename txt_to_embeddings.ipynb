{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c68f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9ea82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"your_dbname\",\n",
    "    user=\"your_username\",\n",
    "    password=\"your_password\",\n",
    "    host=\"your_host\",\n",
    "    port=\"your_port\"\n",
    ")\n",
    "\n",
    "# Create a table to store embeddings with metadata\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS embeddings (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        document_name TEXT,\n",
    "        page_number INTEGER,\n",
    "        text TEXT,\n",
    "        embedding vector(384)  -- Adjust the dimension based on your model\n",
    "    )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "# Assuming PATH_NOTES, chemin_notes, nom_notes, and numero_notes are defined\n",
    "prepro_dir = 'preprocessing'\n",
    "os.makedirs(os.path.join(PATH_NOTES, prepro_dir), exist_ok=True)\n",
    "texte_dir = 'texte'\n",
    "\n",
    "for chemin, nom, numero in tqdm(zip(chemin_notes, nom_notes, numero_notes), desc=\"Processing Notes\"):\n",
    "    pdf = pdfplumber.open(chemin)\n",
    "    note_dir = f\"{nom.split('.')[0]}\"\n",
    "    page_dir = os.path.join(PATH_NOTES, prepro_dir, note_dir, texte_dir)\n",
    "    os.makedirs(page_dir, exist_ok=True)\n",
    "\n",
    "    for idx, page in tqdm(enumerate(pdf.pages), desc=\"Processing Pages\", leave=False):\n",
    "        text = page.extract_text()\n",
    "        text_clean = remove_occurences_3(text)\n",
    "\n",
    "        # Generate embeddings\n",
    "        embedding = model.encode(text_clean)\n",
    "\n",
    "        # Insert embeddings and metadata into the table\n",
    "        with conn.cursor() as cursor:\n",
    "            execute_values(\n",
    "                cursor,\n",
    "                \"INSERT INTO embeddings (document_name, page_number, text, embedding) VALUES %s\",\n",
    "                [(nom, idx + 1, text_clean, embedding.tolist())]\n",
    "            )\n",
    "            conn.commit()\n",
    "\n",
    "        # Optionally, save the cleaned text to a file\n",
    "        with open(f\"{page_dir}/page_{idx+1}.txt\", \"w\", encoding='utf-8') as f:\n",
    "            f.write(text_clean)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
